{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd983b75",
   "metadata": {},
   "source": [
    "# Бэггинг и случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7146970",
   "metadata": {},
   "source": [
    "Загрузите датасет digits с помощью функции load_digits из sklearn.datasets и подготовьте матрицу признаков X и ответы на обучающей выборке y (вам потребуются поля data и target в объекте, который возвращает load_digits)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9921e11d",
   "metadata": {},
   "source": [
    "Для оценки качества далее нужно будет использовать cross_val_score из sklearn.model_selection с параметром cv=10. Эта функция реализует k-fold cross validation c k равным значению параметра cv. Мы предлагаем использовать k=10, чтобы полученные оценки качества имели небольшой разброс, и было проще проверить полученные ответы. На практике же часто хватает и k=5. Функция cross_val_score будет возвращать numpy.ndarray, в котором будет k чисел - качество в каждом из k экспериментов k-fold cross validation. Для получения среднего значения (которое и будет оценкой качества работы) вызовите метод .mean() у массива, который возвращает cross_val_score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726563a6",
   "metadata": {},
   "source": [
    "1. Создайте DecisionTreeClassifier с настройками по умолчанию и измерьте качество его работы с помощью cross_val_score. \n",
    "    Эта величина и будет ответом в пункте 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60b5e2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import pandas as pd\n",
    "from sklearn import datasets, tree, model_selection, ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "digits = load_digits()\n",
    "print(digits.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f3a61f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13eb5fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36c0a5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8246958410924892\n"
     ]
    }
   ],
   "source": [
    "clf         = tree.DecisionTreeClassifier()\n",
    "x_val_score = cross_val_score(clf, X, y, cv=10).mean()\n",
    "print(x_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c1ca88",
   "metadata": {},
   "source": [
    "2. Воспользуйтесь BaggingClassifier из sklearn.ensemble, чтобы обучить бэггинг над DecisionTreeClassifier. Используйте в BaggingClassifier параметры по умолчанию, задав только количество деревьев равным 100. Качество классификации новой модели - ответ в пункте 2. Обратите внимание, как соотносится качество работы композиции решающих деревьев с качеством работы одного решающего дерева."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ed32167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9259404096834263\n"
     ]
    }
   ],
   "source": [
    "bagging_clf = ensemble.BaggingClassifier(clf, n_estimators=100)\n",
    "x_val_score = cross_val_score(bagging_clf, X, y, cv=10).mean()\n",
    "print(x_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b258ed6",
   "metadata": {},
   "source": [
    "3. Теперь изучите параметры BaggingClassifier и выберите их такими, чтобы каждый базовый алгоритм обучался не на всех d признаках, а на корень из d случайных признаков. Качество работы получившегося классификатора - ответ в пункте 3. Корень из числа признаков - часто используемая эвристика в задачах классификации, в задачах регрессии же часто берут число признаков, деленное на три. Но в общем случае ничто не мешает вам выбирать любое другое число случайных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c1db557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9354469273743016\n"
     ]
    }
   ],
   "source": [
    "stoch_train_len = int(sqrt(X.shape[1]))\n",
    "\n",
    "bagging_clf = ensemble.BaggingClassifier(clf, n_estimators=100, max_features=stoch_train_len)\n",
    "x_val_score = cross_val_score(bagging_clf, X, y, cv=10).mean()\n",
    "print(x_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9262aa5d",
   "metadata": {},
   "source": [
    "4. Чтобы выбирать случайные признаки  при построении каждой вершины дерева - нужно убрать выбор случайного подмножества признаков в BaggingClassifier и добавить его в DecisionTreeClassifier. Какой параметр за это отвечает, можно понять из документации sklearn, либо просто попробовать угадать (скорее всего, у вас сразу получится). Попробуйте выбирать опять же корень из d признаков. Качество полученного классификатора на контрольной выборке и будет ответом в пункте 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08e7822b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9354469273743016\n"
     ]
    }
   ],
   "source": [
    "stoch_clf       = tree.DecisionTreeClassifier(max_features=stoch_train_len)\n",
    "bagging_clf     = ensemble.BaggingClassifier(stoch_clf, n_estimators=100)\n",
    "x_val_score_own = cross_val_score(bagging_clf, X, y, cv=10).mean()\n",
    "print(x_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d16723",
   "metadata": {},
   "source": [
    "5. Бэггинг на рандомизированных деревьях\n",
    "Полученный в пункте 4 классификатор - бэггинг на рандомизированных деревьях (в которых при построении каждой вершины выбирается случайное подмножество признаков и разбиение ищется только по ним). Это в точности соответствует алгоритму Random Forest, поэтому почему бы не сравнить качество работы классификатора с RandomForestClassifier из sklearn.ensemble. Сделайте это, а затем изучите, как качество классификации на данном датасете зависит от количества деревьев, количества признаков, выбираемых при построении каждой вершины дерева, а также ограничений на глубину дерева. Для наглядности лучше построить графики зависимости качества от значений параметров, но для сдачи задания это делать не обязательно. \n",
    "\n",
    "    На основе наблюдений выпишите через пробел номера правильных утверждений из приведенных ниже в порядке возрастания номера (это будет ответ в п.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e571275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9487988826815641\n"
     ]
    }
   ],
   "source": [
    "random_forest_clf = ensemble.RandomForestClassifier(random_state=stoch_train_len, n_estimators=100)\n",
    "x_val_score_lib   = cross_val_score(random_forest_clf, X, y, cv=10).mean()\n",
    "print(x_val_score_lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196e3510",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
